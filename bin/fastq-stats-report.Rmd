---
title: "FASTQ quality control metrics"
output:
  html_document:
    highlight: tango
    theme: cosmo
    toc: no
params:
  fqfiles: NULL
---

Report generated on `r Sys.time()` by the [angelovangel/nxf-ont pipeline](https://github.com/angelovangel/nxf-ont)

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE, 
                      echo = FALSE, 
                      warning = FALSE, 
                      cache = FALSE)
require(seqTools)
require(writexl)
require(knitr)
require(kableExtra)
require(dplyr)
require(sparkline)
```

```{r seqtools}
# the seqtools script lives here
# args are individual fastq.gz files

# AUX FUNCTIONS
#=======================================================================
# aux function needed for calc Q20% and Q30%
# phredDist from seqTools returns the phred score distribution, 
# so to get Q20% use get_q(qq, 21) because the vector is zero-based
get_q <- function(qqobj, q) {
	round( sum( phredDist(qqobj)[q:length(phredDist(qqobj))] ) * 100, digits = 2)
}

# aux function to get N50 or Nx from the qq object
# n is 0.5 for N50 etc...
get_nx <- function(qqobj, n) {
	slc <- seqLenCount(qqobj)
	
	# get a vector with read lengths from seq len counts
	v <- rep.int(1:length(slc), times = c(slc))
	
	# and the nice algo for N50
	v.sorted <- rev(sort(v))
	return(list(
		sum_len = sum(v),
		nx = v.sorted[cumsum(v.sorted) >= sum(v.sorted) * n][1]
	))
	
}

#=======================================================================
# start by executing fastqq on the input fqfiles, which are supplied as params by the calling script
cat(params$fqfiles)
qq <- fastqq(params$fqfiles, k = 3)
# because fastqq does not error
if(nFiles(qq) == 0) {
	stop("No valid fastq file found")
}

df <-	data.frame(
			file = basename(qq@filenames),
			num_seqs = qq@nReads,
			sum_len = sapply(1:qq@nFiles, function(x) { get_nx(qq[x], 0.5)$sum_len } ), # total nucleotides
			min_len = seqLen(qq)[1, ],
			max_len = seqLen(qq)[2, ],
			n50 = sapply(1:qq@nFiles, function(x) { get_nx(qq[x], 0.5)$nx } ),
			q20_percent = sapply(1:qq@nFiles, function(x) { get_q(qq[x], 21) } ),
			q30_percent = sapply(1:qq@nFiles, function(x) { get_q(qq[x], 31) } ),
			row.names = NULL
			)

# these files are published by the nxf script
write.csv(df, file = "fastq-stats.csv", row.names = FALSE)
write_xlsx(df, "fastq-stats.xlsx", format_headers = TRUE, col_names = TRUE)

```

***

### Number of reads and read quality metrics

```{r table1, include=TRUE}
df %>%
	kableExtra::kbl(caption = "General fastq files statistics") %>%
	kable_styling(fixed_thead = TRUE, bootstrap_options = c("hover", "responsive"))
```

***

### GC-content, Phred-score and k-mer(3) distributions
```{r table2, include=TRUE}
sparkline(0) # load dependencies
# see https://omnipotent.net/jquery.sparkline/#s-docs
# on how to include both x and y values in spark
# basically, supply values separated by a colon: x:y,x:y,x:y
spark_gc <- function(qqobj, i) {
	spk_chr(paste(names(gcContent(qqobj, i)), ":", round(gcContent(qqobj, i)/qq@nReads[i], 3), sep = ""), 
					# GC content (%) is per Read counts, so to get dist divide by read count
					width = 180, height = 40,
					tooltipFormat = "<span style='color: {{color}}'>&#9679;</span> {{prefix}}avg GC% {{x}} : {{y}} {{suffix}}</span>"
					)
}

spark_phred <- function(qqobj, i) {
	spk_chr(paste(names(phredDist(qqobj, i)), ":", round(phredDist(qqobj, i), 3), sep = ""), 
					width = 180, height = 40,
					tooltipFormat = "<span style='color: {{color}}'>&#9679;</span> {{prefix}}q-score {{x}} : {{y}} {{suffix}}</span>"
					)
}

spark_kmers <- function(qqobj, i) {
	spk_chr(unname(qqobj@kmer[ , i]), width = 320, height = 40, type = "bar")
}

gc_df <- data.frame(
	file = basename(qq@filenames),
	gc_content_dist = sapply(1:qq@nFiles, function(x) { spark_gc(qq, x) }),
	q_score_dist = sapply(1:qq@nFiles, function(x) { spark_phred(qq, x) }),
	# h
	k_mer_dist = sapply(1:qq@nFiles, function(x) { spark_kmers(qq, x) })
)

gc_df %>%
	kableExtra::kbl(escape = F) %>%
	kable_styling(fixed_thead = TRUE, bootstrap_options = c("responsive"))

```

***

